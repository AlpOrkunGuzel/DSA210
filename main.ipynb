{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a1508a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'athlete_events.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m olympics_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mathlete_events.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m      \u001b[38;5;66;03m# <-- gerekirse değiştir\u001b[39;00m\n\u001b[0;32m     31\u001b[0m noc_regions_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoc_regions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m      \u001b[38;5;66;03m# Kaggle Olympic dataset ile birlikte gelir\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m olympics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(olympics_path)\n\u001b[0;32m     34\u001b[0m noc_regions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(noc_regions_path)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOlympics shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, olympics\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\alpog\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\alpog\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\alpog\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\alpog\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\alpog\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'athlete_events.csv'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  DSA210 Term Project\n",
    "#  Comparing National Olympic Success and GDP\n",
    "#  Student: Alp Orkun Güzel - 34524\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 0: Gerekli kütüphaneler\n",
    "# ------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr, ttest_ind\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# Eğer seaborn/statsmodels yüklü değilse (Colab hariç):\n",
    "# !pip install seaborn statsmodels\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 1: Veri Yükleme\n",
    "# ------------------------------------------------------------\n",
    "# 1.1 Olympic athlete_events dataset (Kaggle)\n",
    "# Bu dosyanın adını kendi bilgisayarındaki isimle değiştir:\n",
    "olympics_path = \"athlete_events.csv\"      # <-- gerekirse değiştir\n",
    "noc_regions_path = \"noc_regions.csv\"      # Kaggle Olympic dataset ile birlikte gelir\n",
    "\n",
    "olympics = pd.read_csv(olympics_path)\n",
    "noc_regions = pd.read_csv(noc_regions_path)\n",
    "\n",
    "print(\"Olympics shape:\", olympics.shape)\n",
    "print(\"NOC regions shape:\", noc_regions.shape)\n",
    "display(olympics.head())\n",
    "display(noc_regions.head())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 2: Veri Ön İşleme - Olympics\n",
    "# ------------------------------------------------------------\n",
    "# Sadece Summer Olympics alalım (istersen değiştirilebilir)\n",
    "olympics = olympics[olympics[\"Season\"] == \"Summer\"]\n",
    "\n",
    "# NOC kodlarını ülke isimlerine map etmek için noc_regions kullanıyoruz\n",
    "olympics = olympics.merge(noc_regions[[\"NOC\", \"region\"]], on=\"NOC\", how=\"left\")\n",
    "olympics.rename(columns={\"region\": \"Country_Name\"}, inplace=True)\n",
    "\n",
    "# Madalyası olmayan satırları at (Medal NaN ise, madalya yok)\n",
    "medals = olympics.dropna(subset=[\"Medal\"])\n",
    "\n",
    "# Yıl filtresi: Örneğin 1980 sonrası çalışmak istiyorsan:\n",
    "min_year = 1980\n",
    "medals = medals[medals[\"Year\"] >= min_year]\n",
    "\n",
    "print(\"Filtered medals shape:\", medals.shape)\n",
    "display(medals.head())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 3: Ülke-Yıl Bazında Madalya Sayımı\n",
    "# ------------------------------------------------------------\n",
    "medals_country_year = (\n",
    "    medals\n",
    "    .groupby([\"NOC\", \"Country_Name\", \"Year\"])[\"Medal\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"Medal\": \"Total_Medals\"})\n",
    ")\n",
    "\n",
    "print(\"Medals by country-year shape:\", medals_country_year.shape)\n",
    "display(medals_country_year.head(10))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 4: World Bank Verilerini Yükleme\n",
    "# ------------------------------------------------------------\n",
    "# Burada World Bank'ten indirdiğin CSV dosyalarını kullanmanı öneriyorum.\n",
    "# Genelde World Bank CSV formatı şöyle:\n",
    "# Country Name | Country Code | Indicator Name | Indicator Code | 1960 | 1961 | ... | 2023\n",
    "#\n",
    "# Aşağıdaki fonksiyon, bu formatı uzun forma (Country, Year, Value) çeviriyor.\n",
    "\n",
    "def load_wb_indicator(csv_path, value_name):\n",
    "    \"\"\"\n",
    "    World Bank style wide CSV'yi (yıllar sütun) uzun formata çevirir.\n",
    "    value_name: çıktı kolonu ismi (örn: 'GDP', 'GDP_per_capita', 'Population')\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # İlk 4 kolondan sonrasını yıl sütunları olarak al\n",
    "    value_cols = df.columns[4:]\n",
    "    \n",
    "    df_long = df.melt(\n",
    "        id_vars=[\"Country Name\", \"Country Code\", \"Indicator Name\", \"Indicator Code\"],\n",
    "        value_vars=value_cols,\n",
    "        var_name=\"Year\",\n",
    "        value_name=value_name\n",
    "    )\n",
    "    \n",
    "    # Yıl kolonunu integer yap\n",
    "    df_long[\"Year\"] = pd.to_numeric(df_long[\"Year\"], errors=\"coerce\")\n",
    "    df_long = df_long.dropna(subset=[\"Year\"])\n",
    "    df_long[\"Year\"] = df_long[\"Year\"].astype(int)\n",
    "    \n",
    "    return df_long[[\"Country Name\", \"Country Code\", \"Year\", value_name]]\n",
    "\n",
    "\n",
    "# Bu csv dosyalarının isimlerini kendi indirdiğin dosyalara göre değiştir:\n",
    "gdp_csv_path = \"API_NY.GDP.MKTP.CD_DS2_en_csv_v2.csv\"         # Toplam GDP\n",
    "gdp_pc_csv_path = \"API_NY.GDP.PCAP.CD_DS2_en_csv_v2.csv\"      # GDP per capita\n",
    "pop_csv_path = \"API_SP.POP.TOTL_DS2_en_csv_v2.csv\"            # Population\n",
    "\n",
    "gdp_df = load_wb_indicator(gdp_csv_path, \"GDP\")\n",
    "gdp_pc_df = load_wb_indicator(gdp_pc_csv_path, \"GDP_per_capita\")\n",
    "pop_df = load_wb_indicator(pop_csv_path, \"Population\")\n",
    "\n",
    "print(\"GDP shape:\", gdp_df.shape)\n",
    "print(\"GDP per capita shape:\", gdp_pc_df.shape)\n",
    "print(\"Population shape:\", pop_df.shape)\n",
    "\n",
    "display(gdp_df.head())\n",
    "display(gdp_pc_df.head())\n",
    "display(pop_df.head())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 5: World Bank Verilerini Birleştirme\n",
    "# ------------------------------------------------------------\n",
    "# GDP, GDP_per_capita ve Population'ı tek tabloya alalım\n",
    "econ = gdp_df.merge(gdp_pc_df, on=[\"Country Name\", \"Country Code\", \"Year\"], how=\"outer\")\n",
    "econ = econ.merge(pop_df, on=[\"Country Name\", \"Country Code\", \"Year\"], how=\"outer\")\n",
    "\n",
    "# Yıl filtresi (Olympic verinle aynı aralıkta kalmak için):\n",
    "econ = econ[econ[\"Year\"] >= min_year]\n",
    "\n",
    "print(\"Merged econ shape:\", econ.shape)\n",
    "display(econ.head(10))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 6: NOC -> Country Name eşleştirme ve merge\n",
    "# ------------------------------------------------------------\n",
    "# Olympic verisinde Country_Name, noc_regions'den geliyor (örneğin \"United States\", \"Germany\" gibi)\n",
    "# World Bank'te \"Country Name\" var.\n",
    "# Tam birebir eşleşmeyen bazı ülkeler olabilir, ama ana ülkeler için işe yarar.\n",
    "\n",
    "# İlk olarak merge için basit bir eşleme deneyelim:\n",
    "merged = medals_country_year.merge(\n",
    "    econ,\n",
    "    left_on=[\"Country_Name\", \"Year\"],\n",
    "    right_on=[\"Country Name\", \"Year\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Sadece isim kolonu karmaşasını azaltmak için:\n",
    "merged = merged.drop(columns=[\"Country Name\"])\n",
    "\n",
    "print(\"Final merged shape:\", merged.shape)\n",
    "display(merged.head(20))\n",
    "\n",
    "# Eksik değerleri kontrol edelim:\n",
    "print(\"\\nMissing values (first few columns):\")\n",
    "print(merged[[\"Country_Name\", \"Year\", \"Total_Medals\", \"GDP\", \"GDP_per_capita\", \"Population\"]].isna().sum())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 7: Türev Değişkenler (Normalization)\n",
    "# ------------------------------------------------------------\n",
    "# Bazı ülkelerde GDP veya Population 0 veya NaN olabilir -> bölen yapmadan önce kontrol:\n",
    "merged = merged.copy()\n",
    "\n",
    "# Nüfus > 0 ise kişi başı madalya üretelim\n",
    "merged[\"Medals_per_Million_People\"] = np.where(\n",
    "    (merged[\"Population\"] > 0),\n",
    "    merged[\"Total_Medals\"] / (merged[\"Population\"] / 1_000_000),\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# GDP > 0 ise GDP başına madalya\n",
    "merged[\"Medals_per_Billion_GDP\"] = np.where(\n",
    "    (merged[\"GDP\"] > 0),\n",
    "    merged[\"Total_Medals\"] / (merged[\"GDP\"] / 1_000_000_000),\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "display(merged.head(20))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 8: EDA - Genel Bakış\n",
    "# ------------------------------------------------------------\n",
    "print(\"Merged dataset info:\")\n",
    "print(merged.info())\n",
    "\n",
    "print(\"\\nSummary stats:\")\n",
    "display(merged[[\"Total_Medals\", \"GDP\", \"GDP_per_capita\", \"Population\",\n",
    "                \"Medals_per_Million_People\", \"Medals_per_Billion_GDP\"]].describe())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 9: EDA - Görselleştirme\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# 9.1 Medals vs GDP scatter\n",
    "plt.figure()\n",
    "plt.scatter(merged[\"GDP\"], merged[\"Total_Medals\"])\n",
    "plt.xscale(\"log\")   # GDP çok geniş, log scale daha iyi görünür\n",
    "plt.xlabel(\"GDP (log scale)\")\n",
    "plt.ylabel(\"Total Medals\")\n",
    "plt.title(\"GDP vs Total Medals\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9.2 GDP per capita vs Medals\n",
    "plt.figure()\n",
    "plt.scatter(merged[\"GDP_per_capita\"], merged[\"Total_Medals\"])\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"GDP per capita (log scale)\")\n",
    "plt.ylabel(\"Total Medals\")\n",
    "plt.title(\"GDP per capita vs Total Medals\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9.3 Population vs Medals\n",
    "plt.figure()\n",
    "plt.scatter(merged[\"Population\"], merged[\"Total_Medals\"])\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Population (log scale)\")\n",
    "plt.ylabel(\"Total Medals\")\n",
    "plt.title(\"Population vs Total Medals\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9.4 Korelasyon Heatmap\n",
    "corr_cols = [\"Total_Medals\", \"GDP\", \"GDP_per_capita\", \"Population\",\n",
    "             \"Medals_per_Million_People\", \"Medals_per_Billion_GDP\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(merged[corr_cols].corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 10: Hipotez Testi 1\n",
    "# H0: GDP ile medalya sayısı arasında ilişki yok (ρ = 0)\n",
    "# H1: GDP ile medalya sayısı arasında pozitif korelasyon var (ρ > 0)\n",
    "# ------------------------------------------------------------\n",
    "# Korelasyon için verileri temizleyelim:\n",
    "subset = merged[[\"GDP\", \"Total_Medals\"]].dropna()\n",
    "x = subset[\"GDP\"]\n",
    "y = subset[\"Total_Medals\"]\n",
    "\n",
    "corr, pval = pearsonr(np.log10(x), y)  # log(GDP) kullanmak genelde daha stabil\n",
    "print(\"\\nHipotez 1 - Pearson correlation (log GDP vs medals)\")\n",
    "print(\"Correlation:\", corr)\n",
    "print(\"p-value:\", pval)\n",
    "if pval < 0.05:\n",
    "    print(\">> Sonuç: H0 reddedilir, log(GDP) ile madalya sayısı arasında anlamlı ilişki var.\")\n",
    "else:\n",
    "    print(\">> Sonuç: H0 reddedilemedi, anlamlı ilişki yok.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 11: Hipotez Testi 2\n",
    "# Yüksek GDP'li ülkeler (Top 30%) ile düşük GDP'li ülkelerin\n",
    "# madalya sayıları farklı mı?\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Ülke-yıl düzeyinde değil de biraz daha düzgün karşılaştırma için\n",
    "# istersen aynı yıl içindeki ülkeleri kıyaslayabilirsin, ama basit versiyon:\n",
    "subset2 = merged.dropna(subset=[\"GDP\", \"Total_Medals\"]).copy()\n",
    "threshold = subset2[\"GDP\"].quantile(0.70)\n",
    "\n",
    "high = subset2[subset2[\"GDP\"] >= threshold][\"Total_Medals\"]\n",
    "low = subset2[subset2[\"GDP\"] < threshold][\"Total_Medals\"]\n",
    "\n",
    "t_stat, pval = ttest_ind(high, low, equal_var=False)\n",
    "\n",
    "print(\"\\nHipotez 2 - High GDP vs Low GDP countries (medals)\")\n",
    "print(\"High GDP mean medals:\", high.mean())\n",
    "print(\"Low GDP mean medals:\", low.mean())\n",
    "print(\"t-stat:\", t_stat)\n",
    "print(\"p-value:\", pval)\n",
    "if pval < 0.05:\n",
    "    print(\">> Sonuç: H0 reddedilir, yüksek GDP'li ülkeler istatistiksel olarak daha fazla madalya alıyor.\")\n",
    "else:\n",
    "    print(\">> Sonuç: H0 reddedilemedi, gruplar arasında anlamlı fark yok.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 12: Regresyon Modeli\n",
    "# Total_Medals ~ GDP + GDP_per_capita + Population\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "reg_data = merged[[\"Total_Medals\", \"GDP\", \"GDP_per_capita\", \"Population\"]].dropna().copy()\n",
    "\n",
    "# Log transformlar (scale'leri küçültmek için):\n",
    "reg_data[\"log_GDP\"] = np.log10(reg_data[\"GDP\"])\n",
    "reg_data[\"log_GDP_per_capita\"] = np.log10(reg_data[\"GDP_per_capita\"])\n",
    "reg_data[\"log_Population\"] = np.log10(reg_data[\"Population\"])\n",
    "\n",
    "X = reg_data[[\"log_GDP\", \"log_GDP_per_capita\", \"log_Population\"]]\n",
    "X = sm.add_constant(X)\n",
    "y = reg_data[\"Total_Medals\"]\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(\"\\nOLS Regression Results:\")\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AŞAMA 13: Overperformer / Underperformer Ülkeler\n",
    "# ------------------------------------------------------------\n",
    "# Model yardımıyla beklenen medal sayısı ve residual hesaplayalım:\n",
    "reg_data[\"Predicted_Medals\"] = model.predict(X)\n",
    "reg_data[\"Residual\"] = reg_data[\"Total_Medals\"] - reg_data[\"Predicted_Medals\"]\n",
    "\n",
    "# Residual'ı merged ile birleştirelim ki ülke isimlerini görelim:\n",
    "# reg_data index'i merged ile uyumlu değil, bu yüzden join yapmayacağız,\n",
    "# bunun yerine NOC/Country_Name'i de taşıyalım:\n",
    "\n",
    "# Yeni bir merge için, Index paylaşalım:\n",
    "temp = merged[[\"NOC\", \"Country_Name\", \"Year\"]].join(reg_data[[\"Total_Medals\", \"Predicted_Medals\", \"Residual\"]])\n",
    "\n",
    "# Residual en yüksek (overperform) ülkeler:\n",
    "overperformers = temp.sort_values(\"Residual\", ascending=False).head(15)\n",
    "underperformers = temp.sort_values(\"Residual\", ascending=True).head(15)\n",
    "\n",
    "print(\"\\nTop 15 Overperformers (gerçek > beklenti):\")\n",
    "display(overperformers)\n",
    "\n",
    "print(\"\\nTop 15 Underperformers (gerçek < beklenti):\")\n",
    "display(underperformers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
